%!TEX root = main.tex
\begin{figure*}[ht!]
  \centering
  \vspace{-5pt}
  \includegraphics[width=0.95\linewidth]{figures/zvpp_system.pdf} %5.5
  \vspace{-5pt}\caption{\change{The \zvpp system consist of : (A) data selection panel (where users can select visualized dataset and attributes), (B) query canvas (where the queried data pattern is submitted and displayed), (C) results panel (where the visualizations most similar to the queried pattern is displayed as a ranked list), (D) control panel (where users can adjust various system-level settings), and (E) recommendation (where the typical and outlying trends in the dataset is displayed).}}
  \label{zvOverview}
  \vspace{-5pt}
\end{figure*}
\section{System-level Participatory Design Findings\label{sec:pd_findings}}
%All of the three domains described in the previous section recognized the need for a VQS. As discussed in Section~\ref{sec:methods},
%we worked closely with participants to develop features to address their problems and challenges.
\change{
  Holzblatt and Jones~\cite{HoltzblattJones} describes contextual inquiry as a technique that forms the basis for ``\textit{developing a system model that will support user's work}'' that subsequently ``\textit{fosters participatory design}''. Given the need for a VQS highlighted in contextual inquiry interviews, we further collaborate with participants to develop features to address their problems and challenges. In this section, we first reflect on our feature discovery process to introduce the participatory design (PD) findings, then we provide a high-level system overview of our PD product, \zvpp.
  \subsection{The Collaborative Feature Discovery Process}
  \par Throughout the PD process, we identified various subtasks based on the scientist's workflow and elicited intermediate feedback.
  Bodker et. al.~\cite{BodkerGronbaek} cites the importance of encouraging user participation and creativity in cooperative design through different techniques, such as future workshops, critiques, and situational role-playing. Similarly, our PD objective was to collect as many feature proposals as possible, while being inclusive across different domains. We further organized these features into Table~\ref{bigfeaturetable} through a coding process~\cite{Muller2012} by one of the authors. Using the feature list, example usage scenarios from PD, and similar functionalities in existing VQSs as open codes, we then organized this list into axial codes representing `components': core functionalities that are essential in VQSs. Finally, as we will describe in Section~\ref{sec:sensemaking}, the selective codes represents each of the sensemaking process (denoted by cell colors in Table~\ref{bigfeaturetable}). Given the highly-evolving, undirected nature of exploratory data analysis~\cite{Keim2006,Tukey1970}, this technique comes with its advantages and limitations. User requests (or lack thereof) may not always translate to a direct need. For instance, we found that introducing the newly-added features from \zvpp that addressed a particular use case often results in discovering an unexpected practice usage of the feature with other groups of participants. Having feature proposals inspired by multiple use cases can also lead to more generalized design choice. For example, we spoke to astronomers who wanted to eliminate sparse time series from their visual queries. In the same week, our material science collaborators expressed a need for inspecting only solvents with properties above a certain threshold. Through these use cases, data filtering arose as a crucial, common operation that was later incorporated into \zvpp to support this class of queries.
  %, leading to a comprehensive list of added features listed in Table~\ref{bigfeaturetable}.
  \par While our collective brainstorming led to the cross-pollination and generalization of features, this technique can also lead to unnecessary features that result in wasted engineering efforts. During the design phase, there were numerous problems and features proposed by participants, but not all were incorporated in the tool. Based on our meeting logs with participants, we found that reasons for not taking a feature from the design to implementation stage included:
  \begin{denselist}
  \item Nice-to-haves: One of the most common reasons for unincorporated features comes from participant's requests for nice-to-have features. The amount of nice-to-have features that one could envision for the tool is endless. We use
  two criteria to heuristically judge whether to implement a particular feature:
  \begin{enumerate}[leftmargin=*]
  \item \textit{Necessity:} Without this feature, can the analyst still work with this dataset using the VQS and meet their information needs?
  \item \textit{Generality:} Will this feature benefit only this specific use case or be potentially useful for other domains as well?
  \end{enumerate}
  \item ``One-shot'' operations: We decided not to include features that only needed to be performed once and remain fixed thereafter during the analysis workflow. For example, certain data preprocessing operations such as filtering null values only needed to be performed once with an external tool.
  \item Substantial research or engineering effort: Some proposed features did not make sense in the context of VQS. For example, M3 proposed functional fitting to obtain fitting coefficients. Other features requires a completely different set of research questions. For example, the question of how to properly compute similarity between time series with non-uniform number of datapoints arose in the astronomy and genetics use case, but requires the development of a novel distance metric and algorithm that is out of the scope of our design study objective.
  \item Underdeveloped ideas: Other feature requirements came from casual specification that were underspecified. For example, A1 wanted to look for objects that have deficiency in one band and high emission in another band, but the scientific definition of ``deficiency'' in terms of brightness levels was ambiguous.
  \end{denselist}
  \par Failure to identify these early signs in the design phase may result in feature implementations that turn out not to be useful for the participants. Given exhaustive nature of Table~\ref{bigfeaturetable}, each motivated by example use cases from one or more domains, we further organize the features list in terms of the Section~\ref{sec:sensemaking} sensemaking framework and assess its effectiveness in the Section~\ref{sec:eval_findings} evaluation study.
}
%Our experimental evaluation shows that some of our feature choices also suffer from these pitfalls. For example, we incorporated the feature to reverse the y-axis so that astronomers could better understand magnitude measurements (as larger magnitudes counter-intuitively corresponds to dimmer objects). In hindsight, the feature was not crucial for the analysis since another derived measure present in dataset could be selected instead and the feature was solely specific to the astronomy use case. In the end, we found that this feature was not used by any of the participants (including the proposer) in the user study.

% These longitudinal collaboration led to a list of features that help support these subtasks. Given the , we encouraged participants to ----how VQS features could assist them in their PD
%  which is later organized into a ------ framework in Section ----, and evaluated in ----

% collective brainstorm exercise
% partnership
% during this ---- `what-if'
% with the participant's dataset
% The result of our ----
% The goal of our participatory design process was to collect brainstorm --- a comphrensive list of ----
% encourage creativity and inclusiveness across domains---
% EDA is inherently unstructured process, highly evolving ,etc
%
\input{bigtable}
\change{
  \subsection{System Overview\label{sec:system}}
  The aforementioned features were incrementally incorporated and improved over time as described in the Figure~\ref{timeline} timeline, leading to our final PD product, \zvpp. The \zvpp interface is organized into 5 major regions that dynamically updates upon user interactions. Typically, analysts begin their analysis by selecting the dataset and attribute to visualize in the \emph{data selection panel} (Figure~\ref{zvOverview}A). Then, they specify a pattern of interest as a query (hereafter referred to as \emph{pattern query}), through either sketching, inputting an equation, uploading a data pattern, or dragging and dropping an existing visualization, displayed on the \emph{query canvas} (Figure~\ref{zvOverview}B). \zvpp performs shape-matching between the queried pattern and other possible visualizations and returns a ranked list of visualizations that are most similar to the queried pattern, displayed in the \emph{results panel} (Figure~\ref{zvOverview}C). At any point during the analysis, analysts can adjust various system-level settings through the \emph{control panel} (Figure~\ref{zvOverview}D) or browse through the list of \emph{recommendations} provided by \zvpp (Figure~\ref{zvOverview}E). Our \zvpp system is open source and available at: \url{github.com/[Annonymized for Submission]}.
}
