%!TEX root = main.tex
\section{Participants and Datasets}
During the design study, we observed the participants as they conducted a cognitive walkthrough demonstrating every component of their current data analysis workflow. In this section, we describe our study participants and their use cases to highlight the existing workflow and behavior that participants have adopted for conducting certain analysis tasks~\cite{Nielsen1994}.
\subsection{Astronomy} 
\par The Dark Energy Survey (DES) is a multi-institutional project with over 400 scientists. Scientists use a multi-band telescope that takes images of 300 million galaxies over 525 nights to study dark energy\cite{Drlica-Wagner2017}. The telescope also focuses on smaller patches of the sky on a weekly interval to discover astrophysical transients (objects whose brightness changes dramatically as a function of time), such as supernova explosions or quasars. The output is a time series of brightness observations associated with each object extracted from the images observed.
\par For over five months, we worked closely with an astronomer on the project's data management team working at a supercomputing facility. The scientific goal is to identify a smaller set of potential candidates that may be astrophysical transients in order to study their properties in more detail. \techreport{These insights can help further constrain physical models regarding the formation of these objects.}
\par Participant A1 was interested in \zv as he recognized how specific pattern queries could help scientists directly search for these rare objects. While an experienced astronomer who has examined many transient light curves can often distinguish an interesting transient object from noise by sight, they must visually examine and iterate through large numbers of visualizations of candidate objects. Manual searching is time-consuming and error prone as the large majority of the objects are not astronomical transients.
\techreport{\par If an object of interest or region is identified through the visual analysis, then the astronomer may be interested in inspecting the image of the region for cross-checking that the significant change in brightness of the object is not due to an imaging artifact. This could be done using a custom built web-interface that facilitates the access of cutout images for a queried region of the sky.}

\subsection{Genetics}
\par Gene expression is a common data type used in genomics and is obtained via microarray experiments. \techreport{In these experiments, a grid containing thousands of DNA fragments are exposed to stimuli and measurements for the level at which a gene is expressed are recorded as a function of time.} The data used in the participatory design sessions was the gene expression data over time for mouse stem cells aggregated over multiple experiments.\techreport{, downloaded from an online database\footnote{\url{ncbi.nlm.nih.gov/geo/}}}. We worked with a graduate student and a PI at a research university over three months who were using gene expression data to better understand how genes are related to phenotypes expressed during early development~\cite{Peng2016,Gloss2017}. They were interested in using \zv to cluster gene expression data before conducting analysis with a downstream machine learning workflow.
\par To analyze the data, participant G1 loads the preprocessed data is into a desktop application for visualizing and clustering gene expression data\footnote{\url{www.cs.cmu.edu/~jernst/stem/}}. Participant G1 sets several clustering and visualization parameters on the interface before pressing a button to execute the clustering algorithm. The cluster visualizations are then displayed as overlaid time series for each cluster, as shown in the visualization in Figure \ref{workflow}b. G1 visually inspects that all the patterns in each cluster looks ``clean'' and checks the number of outlier genes that do not fall into any of the clusters.  If the number of outliers is high or the visualizations look unclean, she reruns the analysis by increasing the number of clusters. When the visualized clusters look ``good enough'', G1 exports the cluster patterns into a csv file to be used as features in their downstream regression tasks.
\par Prior to the study, the student (G1) and PI (G3) spent over a month attempting to determine the best number of clusters for their upstream analysis based on a series of static visualizations and statistics computed after clustering. While regenerating their results took no more than 15 minutes every time they made a change, the multi-step, segmented workflow meant that all changes had to be done offline, so that valuable meeting time was not wasted trying to regenerate results. The team had a vested interest in participating in the design of \zv as they saw how the interactive nature of VQSs and the ability to query other time series with clustering results could dramatically speed up their collaborative analysis process.
% \par In the context of a VQS, the main challenge  sure what to look for, need to see typical patterns in dataset

% \techreport{Participant G1 processes the raw microarray data by using a preprocessing script written in R, where she (i) sub-selects 144 genes of interest, (ii) cleans up an experimental artifact due to measurements on multiple probes, (iii) log-transforms the raw data to show a more distinct shape profile for clustering, (iv) normalizes the gene expression values into the range of 0 to 1, and (v) performs Loess smoothing with default parameters to reduce the noise in the data}.}
\subsection{Material Science}
\par We collaborated with material scientists at a research university who are working to identify solvents that can improve battery performance and stability. These scientists work with large datasets containing over 25 chemical properties for more than 280,000 different solvents obtained from simulations.
\par We worked closely with a graduate students, a postdoctoral researcher, and a PI for over a year to design a sensible way of exploring their data using VQSs. Each row of their dataset represents a unique solvent, and consists of 25 different chemical attributes. They wanted to use \zv to identify solvents that not only have similar properties to known solvents but also are more favorable (e.g. cheaper or safer to manufacture), as well as to understand how changes in certain chemical attributes affects them.
\par Participant M1 starts his data exploration process with a list of known and proven solvents as a reference. For instance, he would search for solvents which have boiling point over 300 Kelvins and the lithium solvation energy above 10 kcal/mol using basic SQL queries. This helps him narrow down the list of solvents, and move on to the other properties for similar processing. The scientist also considers the availability and the cost of the solvents while exploring the dataset. When the remaining list of the solvents is sufficiently small, he drills down to more detail (e.g., such as looking at the chemical structure of the solvents to consider the feasibility of conducting experiments with the solvent). While he could identify potential solvents through  manual lookup and comparison,  the process lacked the ability to reveal complicated trends and patterns that might be hidden, such as how the change in one attribute can affect the behavior of other attributes of a solvent. M1 was interested in using a VQS as it was infeasible for him to manually compare between large numbers of solvents and their associated properties manually.


%, as well as their initial challenges they face with VQS during the participatory design process. %We summarize the common properties of and differences between these three groups of researchers in Figure~\ref{example}.

% as well as the ability to filter to data subsets while performing the visual search (e.g. examine only objects classified as stars that have magnitudes above certain threshold). %the main challenge lies in developing mechanisms that allows them to describe the patterns, such as specifying amplitude, etc. %know what to look for but hard to describe and find
These observation inform our ----- search-browse paradigm
