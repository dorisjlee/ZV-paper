%!TEX root = main.tex
\section{Study Findings}
\subsection{Themes Emerging from Participatory Design\label{pd_findings}}
\begin{figure*}[t!]
\centering
\vspace{-15pt}
\includegraphics[width=\linewidth]{figures/system.pdf} %5.5
\vspace{-5pt}\caption{Our VQS after participatory design, which includes: the ability to query via (a) a sketch,(b) input equations, (i) drag and drop, or (j) uploaded patterns; (c) preprocessing via data smoothing; query specification mechanisms including (d) x-range selection and filtering, (e) x-range invariance, (g) Filtering, and (h) Dynamic class creation; recommendation of (k) representative and (l) outlier trends. Prior to the participatory design, \zv only included a single sketch input with no additional options.}
\label{zvOverview}
\vspace{-14pt}
\end{figure*}

\par We employed participatory design with our scientists to incorporate key features missing in our original VQS, and unaddressed in their existing workflows. %We discovered three central themes encapsulating these features that are important to facilitate rapid hypothesis generation and insight discovery, but are missing in prior VQSs. While some of our findings echo prior work on system-level taxonomies of visualization tasks \cite{Amar2005,Heer2012}, we highlight how specific analytic tasks and interaction features could be used to enhance VQSs in particular. \techreport{In particular, we learned that \textit{participants wanted more control over the internals of the systems and an integrated workflow that helped streamline their analysis when using VQSs.}}
\boldpara{Exact Shape Specification} interfaces allows users to submit a query through an exact description of a pattern, then the VQS returns a list of most similar matches. Almost all VQS supports freehand sketching on a virtual canvas through mouse or pen as a intuitive mechanism for specifying a desired patterns (Figure \ref{zvOverview}a). In addition to sketching, \zv also allows users to specify a functional form (e.g. y=$x^2$) for a pattern (Figure \ref{zvOverview}b). This feature was inspired by material scientists who were interested in finding solvents with known analytical models that characterize the relationships between their chemical properties.
\boldpara{Approximate Shape Specification}
While exact shape specification is an intuitive mechanism for constructing a visual query, as pointed out by past works~\cite{correll2016semantics,Holz2009} pattern queries can be extremely imprecise. Many interfaces have developed constrained sketching mechanism to allow users to partially specify certain characteristics, such as angular slope queries for specifying the slope of a trend line~\cite{Hochheiser2004} or piecewise trend querylines over a specified data range~\cite{ryall2005querylines}. Both Qetch and \zv supports data smoothing to allow users to interactively change the degree of shape approximation they would like to apply to all visualizations (and consequently for pattern matching). We develop an interface for users to interactively adjust data smoothing algorithm and parameters on-the-fly to update the resulting visualizations accordingly (Figure \ref{zvOverview}c).
\par During participatory design, both material science and astronomy participants noted the difficulty of shape matching on their dense and noisy observational data and the challenge of picking the appropriate smoothing parameters during offline preprocessing. We found that tight integration between smoothing and visual search additionally tradeoff between the smoothness of the curve and the degree of approximation for shape-matching in VQSs. An over-smoothed visualization would return shape matches that only loosely resemble the query pattern. However, without smoothing, the noise may dominate the overall trend, which could lead to bad pattern matches.
%While the interactions in our original prototype enabled simple visual queries, many scientists were interested in extending their querying capabilities, either through different querying modalities or through more flexible query specification methods.

% While \zv does not attempt to solve all of the pre-processing issues that we faced during participatory design, we identified data smoothing as a common data cleaning procedure that could benefit from a tight integration between pre-processing and visual analysis. Data smoothing is a denoising procedure that generates a smoothed pattern approximating key features of the visualized trend with less noise.
\boldpara{Range Selection}
Often in time series analysis there are specific ranges of time and measure values with special domain specific significance that users may be interested in. One common specification on top of the exact or approximate shape query is limiting the pattern query matched to specific x or y ranges. Range selection can be performed through explicit textbox specification~\cite{wattenberg2001sketching,Mannino2018}, drawing line limits~\cite{ryall2005querylines}, or brushing interactions~\cite{Hochheiser2001}. \zv employs the brushing mechanism to select desirable x-ranges to perform shape matching (Figure \ref{zvOverview}d). Additionally, y axis range selection could be performed through entering a filter constraint on the measure variable.
\par We chose to support only brushing for x, since it was more common to focus the context based on the independent variable in our use cases, such as zooming into particular sharp dips when looking for planetary transits or anomalous peaks indicative of erroneous experimental measurements. In contrast, y-range selection tends to be more global and enforced across multiple interaction sequences, such as looking for only signals above a certain threshold. The TimeSearcher and Queryline approach is most flexible for range selection as they allow composition of multiple range selection to formulate complex piecewise queries, such as finding a gene expression profile rising from x=1$\sim$5 and declining from x=5$\sim$10.
\boldpara{Flexible Matching}
Studies have shown that to facilitate subjectively meaningful pattern matches, VQSs need to support mechanisms for clarifying sketch interpretation and flexible shape matching algorithms~\cite{correll2016semantics,Mannino2018,Eichmann2015}. In \zv, users has the option to change similarity metrics that perform flexible matching (Figure \ref{zvOverview}e), as well as the option to ignore the x-range in shape matching (Figure \ref{zvOverview}f). For finding supernovae, A1 primarily cared about the existence of a peak above a certain amplitude with an appropriate width of the curve, rather than the exact time that the event occurred, leading them to use the consider x-range feature. Geneticist G1 also expressed that she care about when the ``trigger point'' as long as the profile is ``rising''. This latter features is akin to the temporal invariants in SketchQuery~\cite{correll2016semantics}.

\boldpara{Filter Selection}
Past studies in taxonomies of visualization tasks have shown that it is important to design features that enable users to select relevant subsets of data in visual analytics\cite{Amar2005,Heer2012}. We find that users with large datasets first used their domain knowledge to narrow down their search to a subset of data. This increases their chances of finding an interesting pattern for a given pattern query. To filter data, users could compose one or more conditions as filter constraints in a text field (Figure \ref{zvOverview}g). The filtering can be done on data columns associated with each pattern that is not visualized or on the visualized attributes. This feature is unique to \zv as most existing VQSs do not allow users to interact with data in the non-visualized columns.
%We designed two dynamic faceting features coupled with coordinated views that enabled users to specify subsets of data they are querying on and see immediate changes updated in the query, representative, and outlier results.
\boldpara{Group Comparison}
A common analytical question from our participatory design is that users often want to bucket data points into customized classes based on existing properties, and subsequently compare between the customized classes. For example, material scientist M1 wanted to create classes of solvents with ionization potential under -10 kJ/mol, over -8 kJ/mol, and ones between that range. Then, he could browse how visualizations involving lithium solvation energy varied across the three classes. To this end, we implemented dynamic class creation, a feature that allows users to use multiple properties to create custom classes on-the-fly, effectively slicing-and-dicing the data based on their needs (Figure \ref{zvOverview}h). The information regarding the created classes is displayed in the dynamic class information table and as a tooltip over the aggregated visualizations.
% , as shown in Figure~\ref{dcc}.
% \begin{figure}[h!]
% \centering
% \includegraphics[width=\linewidth]{figures/dcc_example.pdf}
% \vspace{-6pt}
% \caption{Example of dynamic classes. (a) Four different classes with different Lithium solvation energies (li) and boiling point (bp) attributes based on user-defined data ranges. (b) Users can hover over the visualizations for each dynamic class to see the corresponding attribute ranges for each class. The visualizations of dynamic classes are aggregate across all the visualizations that lie in that class based on the user-selected aggregation method.}
% \label{dcc}
% \vspace{-10pt}
% \end{figure}
\boldpara{Concept querying}
While input equations are useful when simple analytical models exist, this may not be true for other domains. In these scenarios, users can upload a query pattern of a sequence of points (Figure \ref{zvOverview}i). This is useful for patterns generated from advanced computational models used for understanding scientific processes or prelabelled data from an external reference database. For example, astronomer A1 can upload a query pattern based on synthetic light curves generated from simulations~\cite{Nugent1997} or known supernovae that have been discovered in the past. Similarly, Google Correlate allows users to upload their own time series or enter search keywords that corresponds to a time series.
%, usually as part of the downstream analysis of the exploratory workflow. %For example, the genetics team are trying to develop a time series prediction algorithm using machine learning based on some biological parameters \cite{Peng2016}.
\boldpara{Result querying} allows users to submit a query based on the results, essentially asking for patterns that are similar to the selected data pattern. TimeSearcher allows users instantiate timebox queries by dragging a result visualization and dropping into the query space; QuerySketch does so similarly through double clicking on the visualization. Similarly in \zv, users can drag and drop a visualization in either the results pane or the representative and outliers to the query canvas (Figure \ref{zvOverview}j). The distinction between concept querying and result querying is that concept querying loads in data that are external to the dataset from a reference source, whereas result querying initiates the query using visualizations created from the queried data source.
\boldpara{Recommendation} displays visualizations that may be of interest to the users based on the context of the data. The recommendation feature is unique to \zv, which provides visualizations of representative trends based on clustering and highlights outlier instances that looks different from the rest of the visualizations (Figure \ref{zvOverview}k,l).
\subsection{Evaluation Study Results\label{eval_findings}}
\begin{figure*}[t!]
\minipage{0.6\textwidth}
  \includegraphics[width=\linewidth]{figures/evalstudytimeline.pdf}
  \caption{Timeline of event code and component usage. Black vertical tick indicates a session break, signaling the beginning of a new line of inquiry.}\label{fig:evalstudytimeline}
\endminipage\hfill
\minipage{0.4\textwidth}
  \includegraphics[width=0.8\linewidth]{figures/PENcoding.pdf}
  \caption{Heatmap of features categorized as practical usage (P), envisioned usage (E), and not useful (N).  \techreport{We find that participants preferred to query using bottom-up methods such as drag-and-drop over top-down approaches such as sketching or input equations. Participants found that data faceting via filter constraints and dynamic class creation were powerful ways to compare between subgroups or filtered subsets. The columns are arranged in the order of subject areas and the features are arranged in the order of the three foraging acts.}}\label{fig:feature_heatmap}
\endminipage
\end{figure*}
We recorded audio, video screen captures, and click-stream logs of the participant's actions during the evaluation study. We analyzed transcriptions of these recordings through open-coding and categorized every event in the user study as either a feature usage or via the coding labels:
\begin{denselist}
    \item Insight (Science) \textbf{[IS]}: Insight that connected back to the science (e.g. ``This cluster resembles a repressed gene.'')
    \item Insight (Data) \textbf{[ID]}: Data-related insights (e.g. ``A bug in my data cleaning code generated this peak artifact.'')
    \item Provoke (Science) \textbf{[PS]}: Interactions or observations made while using the VQS that provoked a scientific hypothesis to be generated.
    \item Provoke (Data) \textbf{[PD]}: Interactions or observations made while using the VQS that provoked further data actions to continue the investigation.
    \item Confusion \textbf{[C]}: Participants were confused during this part of the analysis.
    \item Want \textbf{[W]}: Additional features that participant wants, which is not currently available on the system.
    \item External Tools \textbf{[E]}: The use of external tools outside of \zv to complement the analysis process.
\end{denselist}
We map the features to components based on the taxonomy described in Figure~\ref{fig:taxonomy} to obtain Figure~\ref{fig:evalstudytimeline}, which shows the timeline of event codes and component usage for each participant.
\par As shown in Figure \ref{fig:action_heatmap}, to characterize the usefulness of each feature, we also categorized the features into one of the three usage types based on how each feature was used during the study:
\begin{denselist}
    \item Practical usage \textbf{[P]}: Features used in a sensible and meaningful way.
    \item Envisioned usage \textbf{[E]}: Features which could be used practically if the envisioned data was available or if they conducted downstream analysis, but was not performed due to the limited time during the user study.
    \item Not useful \textbf{[N]}: Features that are not useful or do not make sense for the participant's research question and dataset.
\end{denselist}
We chose to derive these labels from the study transcription to circumvent self-reporting bias, which can often artificially inflate the usefulness of the feature or tool under examination. For the remaining paper, we will focus on understanding the design space of VQSs and highlight the takeaways of our study.%developing a process model and design guideline for insight formation in VQSs and divert our thematic analysis of how VQSs fit into the context of an analysis workflow to our technical report.
\begin{figure}[h!]
  \includegraphics[width=\linewidth]{figures/usagefreqbysubject.pdf}
  \caption{A really Awesome Image}\label{fig:usagefreqbysubject}
  % \includegraphics[width=0.8\linewidth]{figures/PENcoding.pdf}
  % \caption{Heatmap of features categorized as practical usage (P), envisioned usage (E), and not useful (N).  \techreport{We find that participants preferred to query using bottom-up methods such as drag-and-drop over top-down approaches such as sketching or input equations. Participants found that data faceting via filter constraints and dynamic class creation were powerful ways to compare between subgroups or filtered subsets. The columns are arranged in the order of subject areas and the features are arranged in the order of the three foraging acts.}}\label{fig:feature_heatmap}
\end{figure}
% These observation inform our ----- search-browse paradigm
% \subsubsection{Discovery of Real-world insights}
% \par Our participants' original workflow often required them to compare between many visualizations manually through separate analysis and visualization steps. Three of the participants cited that this segmented analyze-then-visualize workflow was one of their chief bottlenecks. The cognitive overhead from the segmented workflow made them more hesitant to visualize the results of different parameters and data operations, as A2 noted:
% \begin{quote}
% The quick visualization is something that I could not do on my current framework. I could not query as fast as you do; I need to wait for it, plot, and then compare. Every time I plot, I need to define subplots for 12 visualizations, then its slower. That's the reason why I sometimes plot less, and I rely more on the statistics from the likelihood tests. Sometimes I plot less than I really should be doing.
% \end{quote}
% The ability to rapidly experiment with large numbers of hypotheses in real time is a crucial step in the agile creative process in helping analysts discover actionable insights~\cite{Shneiderman2007a}. Five out of nine participants discussed how the dynamic, interactive update of the visualization in \zv was the main advantage for using VQSs over their original workflow.