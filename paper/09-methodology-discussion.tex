%!TEX root = main.tex
\tvcg{\section{Reflections on Meta-analysis Methodology and Limitations}\label{metastudy} 
\par Design studies are common in visualization research and often culminate to the development of a domain specific tool, such as visualization systems for micro-array data\cite{Craig2003} or biological networks\cite{Barsky2008}. As discussed in Section~\ref{methodology_relatedwork}, unlike these design studies, most prior work in VQSs is technique-driven and is rarely evaluated on real-world user, tasks, and datasets. Prior work distinguishes between problem-driven and technique-driven research and argues that the field of visualization research benefits from contributions made from both types of methodologies\cite{Sedlmair2012,munzner2009nested}. Our work can be seen as a hybrid between problem and technique-driven work by using multiple case studies to more holistically address our research questions.%\dor{Trying to address Karrie's comment "What gap.Not evaluating on real-world task for problem-driven and technique-driven work?"} \sout{Our work seeks to bridge this gap by using multiple case studies to more holistically address our research questions.}
\par When considering a single use case study, our approach closely follows and inherits many of the benefits and pitfalls of MILCs\cite{shneiderman2006strategies}, design studies\cite{Sedlmair2012}, and insight-based evaluations\cite{North2006}. However, there are several additional pros and cons that arises when we consider our multiple case studies approach. 
%\paragraph{P1: Careful selection of case study participants results in early-stage design specification and guidelines.}
\paragraph{P1: Conversation with potential collaborators establishes early-stage design specification and guidelines.} 
\par In selecting our three user groups, we spoke to participants from 12 different potential application domains ranging from connectonomics to protein networks, in a process similar to the \textit{winnow} stage described in \cite{Sedlmair2012}. These conversations drew us to consider what are the viable use cases for VQSs and where VQSs fail, which serves as a starting point for our design study. As a result, we distilled a set of characteristics that exemplifies use cases that may not be suitable for VQSs. We focused on the \astro, \bio, \matsci groups in this paper since their data can be viewed in a line chart format and their tasks required comparisons across many visualizations. It is also important to note that selecting a diverse set of use cases in terms of the types of users, data, challenges and analysis tasks as shown in Figure \ref{example} is important for generalizing our results beyond a single use case.
\par There were many interesting potential scientific use cases that did not satisfy these criteria. For example, time-varying 2D maps representing the interactions between brain regions and protein-protein interactions are non-ordinal heatmaps, with no simple sketching analogy. While VQSs are not restricted to only line charts, supporting querying capabilities for other visualization types is a exciting direction of future work that is outside the scope of this study. Even when the data is time series-based, some potential application domains had data characteristics that made it difficult to use a VQS. For example, a neuroscientist noted that their time series only consists of 3-5  observations, since each observation required the dissection of a mouse brain. Sparse datapoints can be difficult for existing shape matching algorithms. \cut{Small numbers of visualizations to compare against means that VQSs are unnecessary since manual examination may be sufficient to derive insights. \techreport{We also found that to make maximal use of \zv through faceting, their data should contain additional data columns that could support their inference.}} 
%Large, two-dimensional, and ordinal datasets are well suited for VQSs.
\paragraph{P2: Parallel use case engagement results in more generalizable design and development.}
\footnote{While we use the term ``parallel'' in this context, since the process of design studies is highly iterative and subjective to individual participants, the progress of each case study does not have to be exactly in sync. As shown in Figure \ref{timeline}, our participatory design timeline is somewhat scaffolded.} 
%\dor{Addressed Karrie's comment that the generalizability claim is too strong, not sure if need to tone down more.}
\par One of the key benefits of having multiple case studies for a design study is that researchers can better evaluate a relevant set of analysis tasks to be addressed by the tool across use cases. During the design phase, researchers interact with multiple groups of participants to discuss a wide variety of problems present in their current analysis workflows and the types of tasks they want to perform on a VQS. As highlighted in Section \ref{findings}, through a series of cognitive walkthroughs and regular meetings we can distill a set of common themes that emerges across multiple use cases and rank important and relevant problems to address with the tool. Of the 20 features we implemented, 16 were suggested by multiple use cases. 
\par For example, we spoke to to astronomers who wanted to preprocess the data so that sparse time series with few numbers of observations were not included in their dataset. In the same week, we spoke to material scientists who wanted to inspect only solvents with properties above a certain threshold. Through these use cases, data filtering arose as a crucial, common operation that we needed to incorporate into \zv in order to support these class of queries.
\paragraph{P3: Cross pollination of feature design results in unexpected usage.}
In addition to seeking common themes and solutions across use cases, we found that discussing newly-added features that addressed a particular use case with other groups of participants often results in unexpected usage of the feature. Continuing with the filter example, we found that  participants were using filter to do many types of tasks that we did not originally envision in the design study. For example, astronomers reformatted their data and naming scheme to make use of the filter functionality to search across data of selected set of observational cycles, years, or bands. Astronomers and geneticists also used the filter operation to select specific known objects to query similar patterns. Since these unit features were inspired by multiple use cases, they cover a diverse range of foraging acts, as described Section \ref{novel_workflow_foraging}, and thereby support analysts to easily create novel analysis workflows within the VQS.
\paragraph{P4: Conflicting design choices between different users results in feature generalization.}
\kk{This section is confusing}\agp{Why is this a pro?}\dor{This is good because it enables us to create more general features that can tailor to many use cases. I've modified paragraph to make this more clear.}
While there are common features across use cases, we also encounter cases where variations of a feature was required or other use cases that did not want a specific feature. In building a generalized tool, we opted for a default choice that was transparent to the users and a tunable option that the individual users may chose to customize. Many of the options in the systems settings panel such as data smoothing, aggregation options are examples of this. For example, the biologist did not want to turn on smoothing since their data was already Loess smoothed, whereas the astronomers were used to Gaussian Kernel smoothing. Such feature generalization enables us to create features that could be useful across multiple use cases.
\paragraph{C1: Initial collaboration is time-consuming and requires significant effort.} 
The process of preparing the analyst's dataset to be ready to use in our prototype tool for the design study is time-consuming. \kk{Heer might have a paper stating the challenges of preparing data for vis that we should cite}\dor{We could try citing \cite{Kandel2012}, but this is more discussing in the context of our prototype and during the design study process.}This initial phase can largely be boiled down to data requirements and system requirements. In all three of the scientific use cases, there was a period of time for establishing the minimum data and systems requirements for understanding how a visual query system can be used for the particular scientific use case. Data requirements includes gaining sufficient understanding of the problem domain, understanding the types of data suitable for the system, cleaning and loading of the dataset into the tool, so that it is appropriate for use in a VQS. The minimum system requirements include features that are required for the data to be visualized appropriately, such as displaying error bars or showing the time series as scatterplots. Often, participants can only envision the types of queries that they would like to make and how finer query specifications and system controls could help better address their science questions after seeing their data displayed for the first time in the prototype system.
%Data requirements includes gaining sufficient understanding of the problem domain and dataset to help with cleaning and loading of the dataset into the tool, so that it is appropriate for use in a VQS. System requirements involves the features that are required for the analysts to understand their data within in our tool, including --- or ------. %Often the participants can only envision the types of what and how to query can only be obtained after getting over the data and system requirement.
%After seeing the data being displayed for the first time in our system according to these requirements, the scientist naturally begins to envision the types of queries that they would like to make and ways that finer query specifications and system controls that could help better address their science questions.
\paragraph{C2: Failure to select the right problems and features during the design phase can result in wasted engineering efforts.}

\par During the design phase, there were numerous problems and features proposed by participants, but not all were incorporated in the tool. Among our available meeting logs with participants, we found that the reasons for not taking a feature from the design stage to the implementation stage includes: 
\begin{itemize}
\item Nice-to-haves: One of the most common reasons for unincorporated features comes from participant's requests for nice-to-have features. The amount of nice-to-have features that one could envision for the tool is endless. We use 
two criteria to heuristically judge whether to implement a particular feature:
\begin{enumerate}
\item \textit{Necessity:} Without this feature, can the analyst still work with this dataset using our tool and achieve what they want to do? 
\item \textit{Generality:} If this feature was implemented, will it benefit only this specific use case or be potentially useful for other applications as well?
\end{enumerate}
\item ``One-shot'' operations: We decided not to include features that were ``one-shot'' operations that only needed to be performed once during the analysis workflow. For example, certain data preprocessing operations such as filtering null values only needed to be performed once unlike the data smoothing feature that we added, which was a preprocessing step that could be iteratively performed along with other operations in the VQS. This design choice is specific to our VQS design study.
\item Substantial research or engineering effort: Some proposed features do not make sense in the context of VQS. For example, the \matsci group proposed functional fitting to obtain fitting coefficients. Other features requires a completely different set of research questions. For example, the question of how to properly compute similarity between time series with non-uniform number of datapoints arose in the astronomy and genetics use case, but requires the development of a novel distance metric or algorithm that is out of the scope of the RQs of our design study.
\item Underdeveloped ideas: Other feature requirements came from casual specification that were underspecified. For example, A1 wanted to look for objects that have deficiency in one band and high emission in another band, but what brightness levels qualifies as deficiency is ambiguous.
\end{itemize}
\par Failure to identify these early signs in the design phase may result in features implementations that turn out not to be useful for the participant. 
%(true also for single design study, but here we need to make a decision on evaluate what to build instead of simply building so that it works for a single use case.) 
Our experimental evaluation shows that some of our features choices also suffer from these pitfalls. For example, we incorporated the feature to reverse y-axis so that astronomers could better understand magnitude measurements (as larger magnitudes counter-intuitively corresponds to dimmer objects). In hindsight, the feature was not crucial for the analysis since another derived measure present in dataset could be selected instead and the feature was solely specific to the astronomy use case. In the end, we found that this feature was not used by any of the participants (including the proposer) in the user study.%For example, we incorporated error bars since astronomers were unable to make sense of the raw data pattern and distinguish between a real supernovae signal from fluctuations caused by noise. While we initially thought that uncertainty measurements would be a common theme across experimental data in the physical sciences, this feature was only used for the specific astronomy dataset in the study. 
}