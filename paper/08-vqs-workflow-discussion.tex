%!TEX root = main.tex
\section{VQSs within a scientific data analysis workflow (R4)}
\ccut{We also gained insights into how VQSs can potentially integrate with scientists' existing workflows. We start by identifying properties of ideal datasets for VQSs.}
\subsection{VQSs used beyond the exploration stage of analysis.} 
\par \techreport{Two of the five datasets used in the user study were preliminary in the sense that the scientists had performed only basic data cleaning and had not explored this dataset in great detail themselves \tvcg{(A1, G2)}. This enabled us to get a sense of how VQSs can be used in practice at different stages of the analysis workflow.} \tvcg{During the participatory design, we thought that our VQS would serve as a tool that help scientists find interesting patterns} following which scientists could proceed to a more detailed and rigorous analysis based on these newly-obtained insights. We realized after the evaluation study that users were interested in using VQSs for more than one-step pattern-finding. For example, A2 commented:
\begin{quote}
[\zv fits in] after the cleaning and after correcting for systematics, I will use \zv for a first visualization, not taking the advantage of all the features that \zv has, and then will perform a first analysis and then come back to \zv (in this analysis I will calculate the rotational period and some other values that could help me separate out the categories in \zv), then after I learn about the categories. In the end, I will again use \zv to visually inspect the data. %In stellar astronomy, visual inspection is super high rated [sic].
\end{quote}
Participants also explained where they saw VQS fit into their workflow, including {\em (i)}
visualizing raw data before cleaning to learn about what types of outliers, representative trends, and artifacts are present in the data (A1, A2, G2, M3); {\em (ii)}
 data verification after cleaning to see if known patterns show up as expected (G1);
 and {\em (iii)}
verifying the correctness of a simulation, by visualizing data from a simulation that is based on insights obtained using the VQS (G1, G3).
\subsection{VQSs can be used for verifying data fidelity and debugging.}
\par Participants often used \zv to verify the fidelity of their data and perform debugging. For example, G2 crosschecked that there were no data artifacts of ``genes with two peaks'' via sketching.  Via the visualizations displayed in the result, representative, and outlier panels in \zv, participants were able to gain a peripheral overview of the data and spot anomalies during exploration. For example, A1 spotted time series that were too faint to look like stars after applying a filter constraint of CLASS\_STAR=1. After a series of visualizations of other query results and consultation with an external database, he concluded that the dataset had been incorrectly labelled with all the stars with CLASS\_STAR=0 as 1 during data cleaning. 
\par Explanatory display outputs \tvcg{in the VQS} work closely in conjunction with finer control mechanisms so that users receive feedback on their data actions and immediately update their mental models. For example, the genetics participants modified the clustering parameters and verified that the size of each cluster still remained relatively even, in order to determine the best values of the parameters. This served as a verification mechanism that helped users build trust in the model outputs by cross checking with their intuition on what should happen to the result as they perform an operation \cite{Chuang2012}. Moreover, the dynamic, real-time update of VQSs aid rapid hypothesis generation and encourage scientists to try things that they would not have done otherwise, especially for exploratory tasks that had a low probability of producing interesting results, such as browsing for anomalies \tvcg{as a sanity check} or data verification. 
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{VQSs are used in conjunction with external tools.}
\par During the user study, four of the scientists consulted external tools outside of the VQS as a reference. Two out of the four used the external tools to compute statistics, browse related datasets, or examine other data attributes. This shows that generic VQSs are not a one-size-fits-all solution~\cite{stonebraker2005one}, and domain-specific tools are often useful to provide context.
\techreport{\par For example, A1 saw a strange dip in the time series in the VQS and wanted to see whether it was an artifact. He first checked the database to see if there is an error flag associated with the observation of this object and learned that this object is labelled as a galaxy. Upon comparing with the other visualization in the panel in the VQS, he noticed the difference in y values and hypothesized that object was so faint that it was below the detection limit of the instrument. After going to an external software to inspect the images, he verified his hypothesis as the image was so noisy and a bright nearby star may have saturated the imaging equipment and resulting in the dip in the observations.}
\par We identified two main reason why scientists go to external tools to support their analysis in VQS. (1) Scientists often require multiple sources of data to test the validity of their hypothesis. For example, to determine whether a particular gene belongs to a regulatory network, G2 not only looks at the expression data in the VQS but also enrichment testing and knockout data. Visualizing these data often requires specialized tools and isn't  supported by a generic VQS. To enable smoother transitions between tools, several participants expressed that VQSs should bookmark and track the history of visualizations that they had found interesting. (2) Scientists also use many different data attributes to better understand the data that they are visualizing in the VQS and further develop their hypotheses. Four participants wanted the VQS to support data summaries (histograms, statistics) on the non-visualized attributes to assist them with choosing appropriate values for filtering data subsets and class creation. For instance, A2 used his Jupyter Notebook during  exploration to obtain summary statistics on radius of a star. 
\subsection{Insights derived as preliminary, and can be subjected to more robust testing or \cut{supported their intuition for more advanced }downstream modeling.}
\par We ask participants the types of additional analysis they plan to run downstream after obtaining insights from \ourVQS. Eight out of nine participants envisioned that exporting functionalities in \zv are useful for directing them to the next step of their analysis workflow. For astronomers, the post-analysis tasks involve cross-checking and inspecting individual objects of interest more closely, including using external data types such as images. A1 discussed how he plans to perform a more rigorous ``blind analysis'', which involves taking the visualized data without any IDs or associated data attribute, and seeing if other statistical techniques yields the same set of interesting objects as the ones discovered visually through VQS. All genetics participants expressed that they will export the clusters and directly move onto the next stage of the analysis without additional verification, since they regard the results from VQS ``simply as guidelines'' (G3) that provide them with the intuition about what types of patterns exist in their dataset, before they start building advanced models. \tvcg{None of the material scientist} wanted to export their data because they were more interested in insights gained from understanding relationships between chemical properties, rather than finding particular solvents. The question of how analysts understand and trust the outputs of VQS depending on the objectives of their analysis is an interesting direction for future work.