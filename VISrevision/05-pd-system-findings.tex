%!TEX root = main.tex
 %\section{System-level Participatory Design Findings\label{sec:pd_findings}}
 \input{bigtable_new}
 \section{\rchange{Design} Process and System Overview\label{sec:pd_findings}}
%All of the three domains described in the previous section recognized the need for a VQS. As discussed in Section~\ref{sec:methods},
%we worked closely with participants to develop features to address their problems and challenges.
 Given the need for a VQS, we further collaborated with participants to develop features to address their problems and challenges \rchange{in Phase II of our study}. We \rchange{first provide a high-level system overview of the \rchange{design} product, \zvpp, then we reflect on our feature discovery process}.
 \subsection{System Overview\label{sec:system}}% as described in the Figure~\ref{timeline} timeline
 % \rchange{Table~\ref{bigfeaturetable} highlights the major capabilities in our final \cut{PD product}\rchange{prototype}, \zvpp. Details of other features in \zvpp can be found in the} appendix and online documentation\footnote{Documentation: \url{http://github.com/zenvisage/zenvisage/wiki}}. 
  The \zvpp interface is organized into 5 major regions all of which dynamically update upon user interactions. Typically, participants begin their analysis by selecting the dataset and attributes to visualize in the \emph{data selection panel} (Figure~\ref{zvOverview}A). Then, they specify a pattern of interest as a query (hereafter referred to as \emph{pattern query}), through either sketching, inputting an equation, uploading a data pattern, or dragging and dropping an existing visualization, displayed on the \emph{query canvas} (Figure~\ref{zvOverview}B). \zvpp performs shape-matching between the queried pattern and other possible visualizations, and returns a ranked list of visualizations that are most similar to the queried pattern, displayed in the \emph{results panel} (Figure~\ref{zvOverview}C). At any point during the analysis, analysts can adjust various system-level settings through the \emph{control panel} (Figure~\ref{zvOverview}D) or browse through the list of \emph{recommendations} provided by \zvpp (Figure~\ref{zvOverview}E). For comparison, the existing \zv system \cut{(Figure~\ref{oldZV} in Appendix~\ref{apdx:pdartifact}) }from~\cite{Siddiqui2017} allowed users to query via sketching or drag-and-drop and displayed representative and outlier pattern recommendations, but had limited capabilities to navigate across different data subsets and had few control settings. Our \zvpp system is open source and available at: \url{http://github.com/zenvisage/zenvisage}; \rchange{other details and documentation can be found at that link}. %\techreport{Our \zvpp system is open source and available at: \url{github.com/[Annonymized for Submission]}.}
 \subsection{The Collaborative Feature Discovery Process~\label{sec:feature_dsicovery}}
 \par Throughout the \rchange{design} process, we worked closely with participants to discover VQS capabilities that were essential for addressing their high-level domain challenges. We identified various subtasks based on the participant's workflows, designed sensible features for accomplishing these subtasks that could be used in conjunction with existing VQS capabilities, and elicited feedback on intermediate feature prototypes. Bodker et al.~\cite{BodkerGronbaek} cite the importance of encouraging user participation and creativity in cooperative design through different techniques, such as future workshops, critiques, and situational role-playing. Similarly, our objective was to collect as many feature proposals as possible\cut{, while being inclusive across different domains}. We further organized these features \rchange{we added to \zvpp} into Table~\ref{bigfeaturetable} through an iterative coding process~\cite{Muller2012} by one of the authors.
 \par \cut{In grounded theory methods~\cite{Muller2012}, researchers first create \emph{open codes} to assign descriptive labels to raw data, followed by grouping open codes together by relationships or categories to form \emph{axial codes}. Finally, \emph{selective codes} are obtained by focusing on specific sets of axial codes to come up with a set of core emerging concepts. Inspired by grounded theory methods,} We first collected the list of features\rchange{, }example usage scenarios\rchange{, }and similar capabilities in existing VQSs as open codes\rchange{, corresponding to individual rows in Table~\ref{bigfeaturetable}}. Then, we further organized this list into axial codes representing ``components''\rchange{: core functionalities essential to VQSs (second} column in Table~\ref{bigfeaturetable}). Finally, \cut{as we will describe in Section~\ref{sec:sensemaking}, }the selective codes capture each of the sensemaking processes (\rchange{leftmost column} in Table~\ref{bigfeaturetable}). Instead of describing this table in detail, we present a typical example of how this table is organized. \rchange{From right to left, consider the row corresponding to the Smoothing feature (column 3) in} Table~\ref{bigfeaturetable}: one of the common challenges in astronomy and material science is that noise in the dataset can result in large numbers of false-positive matches. To address this issue, smoothing is a feature in \zvpp that enables users to adjust data smoothing algorithms and parameters on-the-fly to both denoise the data and change the degree of shape approximation applied when performing pattern matching. %smoothing is a feature in \zvpp that enables users to adjust data smoothing algorithms and parameters on-the-fly to both denoise the data and change the degree of shape approximation applied to all visualizations when performing pattern matching. This is useful for domains such as astronomy and material science where the dataset is noisy with large numbers of false positives that could be matched to any given pattern query. 
 Smoothing, along with range selection and range invariance\cut{(row 5 and 6)}, is part of the \emph{match specification} component: VQS mechanisms for clarifying how matching should be performed. Both match specification and \emph{pattern specification} (a description of what the pattern query should look like) are essential components for supporting the sensemaking process top-down pattern search (in blue\rchange{, as labeled in the leftmost column}).%, described in Section~\ref{sec:sensemaking}.
 % Smoothing is also supported in Qetch~\cite{Mannino2018}. Other interfaces have also developed constrained sketching mechanisms to allow users to partially specify certain shape characteristics, such as angular slope queries\techreport{for specifying the slope of a trend line}~\cite{Hochheiser2004} or piecewise trend querylines\techreport{over a specified data range}~\cite{ryall2005querylines}. Smoothing was chosen over these other interfaces for approximating key patterns in the data, since it was a familiar preprocessing step in our study participants' workflow.
 %, where we began with an existing VQS (\zv, as illustrated in Figure~\ref{oldZV}) and incrementally incorporated features, such as dynamic class creation (Figure~\ref{dcc}), throughout the PD process.
 \cut{\begin{figure}[h!]
 	\centering
 	% \captionsetup{justification=centering,margin=2cm}
 	% \includegraphics[width=6in]{figures/timeline.pdf}
   \includegraphics[width=\linewidth]{figures/timeline.pdf}
 	\caption{Timeline for progress in participatory design studies.}
 	\label{timeline}
 	% \vspace{-10pt}
 \end{figure}}
 \par It is important to note that while some of the proposed features in Table~\ref{bigfeaturetable} (such as data filtering and view specification) are pervasive in general visual analytics (VA) systems~\cite{Heer2012,Amar2005}, they have not been incorporated in present-day VQSs. In fact, one of the key insights here is in recognizing the need for an \emph{integrative} VQS whose sum is greater than its parts, that encourages analysts to rapidly generate hypotheses and discover insights by facilitating all three sensemaking processes. This finding is partially enabled by the unexpected benefits that come with collaborating with multiple groups of participants during the feature discovery process. \rchange{Next, we reflect on what worked and what didn't work in the feature discovery process, to inform similar design studies for visual analytics systems.
 % Given the highly-evolving, ad-hoc nature of exploratory data analysis~\cite{Keim2006,Tukey1970}, our collaborative feature discovery approach for aiding such analysis comes with its advantages and limitations. We distill these experiences into four separate themes to inform future visual analytics research that adopts a user-centered design approach.
 % 
 }
 \rchange{
 \par \stitle{Cross-pollination and Generalization via Parallel Use Cases.}} Introducing the newly-added features to \zvpp that addressed a particular domain often resulted in unexpected use cases for other domains. Considering feature proposals from multiple domains can also \rchange{result in cross-pollination of feature designs, often leading to} more generalized design choices. For example, around the same time when we spoke to astronomers who wanted to eliminate sparse time series from their search results, our material science collaborators also expressed a need for inspecting only solvents with properties above a certain threshold. \rchange{Instead of developing separate domain-specific features,} data filtering arose as a crucial, common operation that was later incorporated into \zvpp to support this class of queries. %User requests (or lack thereof) may not always translate to a direct need.
 %, leading to a comprehensive list of added features listed in Table~\ref{bigfeaturetable}.
 % \agp{should we have topic sentences to organize takeaways better}
 \begin{figure*}[ht!]
   \centering
   \vspace{-5pt}
   \includegraphics[width=0.9\linewidth]{figures/zvpp_system.pdf} %5.5
   \vspace{-5pt}\caption{The \zvpp system consists of : (A) data selection panel (where users can select visualized dataset and attributes), (B) query canvas (where the queried data pattern is submitted and displayed), (C) results panel (where the visualizations most similar to the queried pattern are displayed as a ranked list), (D) control panel (where users can adjust various system-level settings), and (E) recommendations (where the typical and outlying trends in the dataset is displayed).}
   \label{zvOverview}
   \vspace*{-10pt}
 \end{figure*}
 \rchange{
 \par \stitle{The Hidden Upfront Cost of Domain Integration.} While we expected to spend most of our collaborative design effort on figuring out the mechanics of visual query specification and matching, instead, preparing participant datasets for use in our system by meeting data and system requirements was the most time-consuming aspect of this phase. (We provide a detailed timeline in Appendix~\ref{xxx}\agp{plz add..})
 Data requirements include gaining an understanding of the problem domain, understanding the types of data suitable for a VQS, and cleaning and loading of this data. 
 System requirements include features required for the data to be visualized appropriately. 
 Often, participants could only envision the types of queries to issue and how variations to the system controls or mechanics could help better address their needs after seeing their data displayed for the first time in the prototype. 
 We also found that the time it took us to satisfy the data and system requirements decreased as we progressed to the later domains, by leveraging existing features in our prototype to satisfy some of
 the upfront needs. 
 \cut{In summary, it is important to allocate sufficient time when working with real-world datasets and users to account for initial system and data challenges, as well as developing general-purposed integration features (such as data uploading tools) that could be used across multiple use cases to decrease the upfront cost for future collaborations with new domains.}
 \par \stitle{Build Connectors, not Swiss-Army Knives.} Participants often envisioned how VQSs can be used in conjunction with other resources that they are familiar with, including those used for reference,
 computing statistics, browsing related datasets, or examining other data attributes or visualization types not supported in the VQS (scatterplots, histograms). The prevalence of external tools for supporting analytical inquiries stems from how analysts often require multiple data sources or data attributes to further develop or verify their hypothesis. For example, to determine whether a particular gene belongs to a regulatory network, G2 not only needed to look at the expression data in the VQS, but also enrichment testing and knockout data. Likewise, others used specialized tools for visualizing telescope images and 3D chemical structures. Instead of forcing our VQS prototype into a swiss-army knife, we instead focused on building connectors that enable smoother transitions between tools. For example, our data upload and pattern upload feature invites participants to bring data from an external tool into \zvpp, while our data export feature allowed users to download the similarity, representative trend, and outlier results as csv files from \zvpp into an external tool\cut{for downstream analysis, or export individual visualizations to facilitate easier sharing of visualization results with collaborators}. For example, geneticists could export the clusters directly from \zvpp as inputs to their downstream regression analysis.
 %Amongst these, data uploading is system ----, --- developing an extensive----.
 \npar \stitle{The Art of Problem Selection.}} While our collective brainstorming led to the cross-pollination and generalization of features, this technique can also lead to unnecessary features that result in wasted engineering effort. \rchange{During co-design}, there were numerous \cut{problems and associated }features proposed by participants, not all of which were incorporated. \rchange{The reasons for not carrying a feature from design to implementation stage included:
 \begin{denselist} %he amount of nice-to-have features that one could envision for the tool is endless.
 \item Nice-to-haves: One of the most common reasons for unincorporated features comes from participant's requests for nice-to-have features. We use two criteria (necessity and generality across domains) to judge whether to invest in developing a particular feature.
 % To this end, we use two criteria to heuristically judge whether to implement a particular feature:
 % \begin{enumerate}[leftmargin=*]
 % \item \textit{Necessity:} Without this feature, can participants still work with this dataset using the tool and meet their information needs?
 % \item \textit{Generality:} Will this feature benefit only this specific use case or be potentially useful for other domains as well?
 % \end{enumerate}
 \item ``One-shot'' operations: We decided not to include features that only needed to be performed once and remain fixed thereafter in the analysis workflow. For example, certain preprocessing operations such as filtering null values only needed to be performed once with an external tool, whereas data smoothing is a procedure that requires some degree of tuning and adjustments.
 \item Substantial research or engineering effort: Some proposed features did not make sense in the context of VQS or required a completely different set of research questions. For example, the question of how to properly compute similarity between time series with non-uniform number of datapoints arose in the astronomy and genetics use case, but requires the development of a novel distance metric and algorithm that is out of the scope of our design study objective. %. For example, M3 proposed functional fitting to obtain fitting coefficients. Other features
 \item Underdeveloped ideas: Other feature requirements came from casual specification that was underspecified. For example, A1 wanted to look for objects that have a deficiency in one band and high emission in another band, but the scientific definition of ``deficiency'' in terms of brightness levels was ambiguous.
 \end{denselist}
 \npar The decision of whether to invest in developing a feature requires a careful balance between promoting unforseen feature and wasted engineering efforts. Failure to identify these early signs may result in feature implementations that turn out not to be useful for the participants or result in feature bloat.
 } 
 % We detail the list of criteria that was used to determine whether to implement a proposed feature (including eliminating features that were nice-to-have, one-shot operations, non-essential, or required a substantially different set of research questions) in Appendix~\ref{apdx:pdartifact}\agp{Give Examples, organize as insights}.
 